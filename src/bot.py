import asyncio
import logging
from aiogram import Bot, Dispatcher, types
from aiogram.filters import CommandStart
from aiogram.types import Message, InlineKeyboardMarkup, InlineKeyboardButton, CallbackQuery

# üêç –ò–∑—É—á–∞–µ–º: –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã –≤–Ω—É—Ç—Ä–∏ –ø–∞–∫–µ—Ç–∞
# –¢–æ—á–∫–∞ (.) –æ–∑–Ω–∞—á–∞–µ—Ç "–∏–∑ —ç—Ç–æ–π –∂–µ –ø–∞–ø–∫–∏" (–∏–∑ src)
from .llama_client import LlamaClient
from .context_manager import ContextManager

# –ê —ç—Ç–æ—Ç –∏–º–ø–æ—Ä—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç, —Ç.–∫. –º—ã –∑–∞–ø—É—Å–∫–∞–µ–º –∏–∑ –∫–æ—Ä–Ω—è `LocalAiChat`
from config_example import BOT_TOKEN

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ ---
# üêç –ò–∑—É—á–∞–µ–º: –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã
# –≠—Ç–∏ –æ–±—ä–µ–∫—Ç—ã —Å–æ–∑–¥–∞—é—Ç—Å—è –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤–æ –≤—Å–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏.
# –≠—Ç–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ, —Ç.–∫. –º—ã –Ω–µ —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∏ –º–µ–Ω–µ–¥–∂–µ—Ä—ã –ø—Ä–∏ –∫–∞–∂–¥–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏.
bot = Bot(token=BOT_TOKEN)
dp = Dispatcher()
llama_client = LlamaClient()
context_manager = ContextManager()


# --- –ö–ª–∞–≤–∏–∞—Ç—É—Ä—ã ---
def get_reset_keyboard() -> InlineKeyboardMarkup:
    """–°–æ–∑–¥–∞–µ—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç inline-–∫–ª–∞–≤–∏–∞—Ç—É—Ä—É."""
    keyboard = InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="üîÑ –°–±—Ä–æ—Å–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç", callback_data="reset_context")]
    ])
    return keyboard


# --- –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–æ–º–∞–Ω–¥ –∏ callback'–æ–≤ ---
@dp.message(CommandStart())
async def command_start_handler(message: Message) -> None:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start."""
    user_id = message.from_user.id
    context_manager.clear_context(user_id)
    await message.answer(
        "üîÑ –î–∏–∞–ª–æ–≥ —Å–±—Ä–æ—à–µ–Ω!\n\n"
        "üëã –ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç –Ω–∞ –±–∞–∑–µ LLaMA –º–æ–¥–µ–ª–∏. –ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ –º–Ω–µ.",
        reply_markup=get_reset_keyboard()
    )
    logging.info(f"User {user_id} started the bot and cleared context.")


@dp.callback_query(lambda c: c.data == 'reset_context')
async def callback_reset_context(callback: CallbackQuery):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –Ω–∞–∂–∞—Ç–∏—è –Ω–∞ –∫–Ω–æ–ø–∫—É —Å–±—Ä–æ—Å–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞."""
    user_id = callback.from_user.id
    context_manager.clear_context(user_id)
    await callback.answer("üîÑ –ö–æ–Ω—Ç–µ–∫—Å—Ç —Å–±—Ä–æ—à–µ–Ω!")
    await callback.message.edit_text(
        "üîÑ –ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ —Å–±—Ä–æ—à–µ–Ω!\n\n–ú–æ–∂–µ—Ç–µ –Ω–∞—á–∞—Ç—å –Ω–æ–≤—ã–π —Ä–∞–∑–≥–æ–≤–æ—Ä.",
        reply_markup=get_reset_keyboard()
    )
    logging.info(f"User {user_id} cleared context via button.")


# --- –û—Å–Ω–æ–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–æ–±—â–µ–Ω–∏–π ---
@dp.message()
async def chat_handler(message: Message) -> None:
    """–û—Å–Ω–æ–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –¥–∏–∞–ª–æ–≥–∞ —Å LLaMA."""
    user_id = message.from_user.id
    user_text = message.text
    
    # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –ø—É—Å—Ç—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
    if not user_text:
        return

    logging.info(f"Received message from {user_id}: '{user_text}'")

    try:
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º, —á—Ç–æ –±–æ—Ç "–ø–µ—á–∞—Ç–∞–µ—Ç"
        await bot.send_chat_action(user_id, 'typing')

        # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –∏—Å—Ç–æ—Ä–∏—é
        context_manager.add_message(user_id, "user", user_text)
        current_context = context_manager.get_context(user_id)

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ LLaMA
        llama_response = await llama_client.send_message(user_text, current_context)

        if llama_response:
            context_manager.add_message(user_id, "assistant", llama_response)
            context_info = context_manager.get_context_info(user_id)
            response_with_info = (
                f"{llama_response}\n\n"
                f"üíæ –ö–æ–Ω—Ç–µ–∫—Å—Ç: {context_info['messages']}/{context_info['max_messages']}"
            )
            await message.answer(response_with_info, reply_markup=get_reset_keyboard())
        else:
            await message.answer(
                "üòî –ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ –º–æ–≥—É —Å–µ–π—á–∞—Å –æ—Ç–≤–µ—Ç–∏—Ç—å. –ü—Ä–æ–±–ª–µ–º–∞ –Ω–∞ —Å—Ç–æ—Ä–æ–Ω–µ –ò–ò-–º–æ–¥–µ–ª–∏. "
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
                reply_markup=get_reset_keyboard()
            )

    except Exception as e:
        logging.error(f"Error processing message for user {user_id}: {e}", exc_info=True)
        await message.answer(
            "üòî –ü—Ä–æ–∏–∑–æ—à–ª–∞ –≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–±—Ä–æ—Å–∏—Ç—å –¥–∏–∞–ª–æ–≥.",
            reply_markup=get_reset_keyboard()
        )


# --- –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ ---
async def main() -> None:
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –±–æ—Ç–∞."""
    logging.info("Starting bot...")

    if not await llama_client.check_server_health():
        logging.warning("LLaMA server is not available. The bot may not function correctly.")
    else:
        logging.info("LLaMA server is available.")

    # –ó–∞–ø—É—Å–∫ long-polling
    await dp.start_polling(bot)


if __name__ == '__main__':
    try:
        asyncio.run(main())
    except (KeyboardInterrupt, SystemExit):
        logging.info("Bot stopped.")
    except Exception as e:
        logging.critical(f"Bot failed to start: {e}", exc_info=True) 