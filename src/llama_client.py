import requests
import json
from typing import Optional
from config_example import LLAMA_SERVER_URL, REQUEST_TIMEOUT


class LlamaClient:
    """
    –ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å LLaMA —Å–µ—Ä–≤–µ—Ä–æ–º
    """
    
    def __init__(self, server_url: str = LLAMA_SERVER_URL):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞
        """
        self.server_url = server_url.rstrip('/')
        self.timeout = REQUEST_TIMEOUT
    
    async def send_message(self, message: str, context: Optional[str] = None) -> Optional[str]:
        """
        –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ LLaMA –∏ –ø–æ–ª—É—á–∞–µ—Ç –æ—Ç–≤–µ—Ç
        """
        try:
            if context:
                full_prompt = f"{context}\nUser: {message}\nAssistant:"
            else:
                full_prompt = f"User: {message}\nAssistant:"
            
            payload = {
                "prompt": full_prompt,
                "max_tokens": 512,
                "temperature": 0.7,
                "stop": ["User:", "\n\n"]
            }
            
            print(f"üöÄ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ LLaMA: {self.server_url}/completion")
            
            response = requests.post(
                f"{self.server_url}/completion",
                json=payload,
                timeout=self.timeout
            )
            
            if response.status_code == 200:
                result = response.json()
                answer = result.get("content", "").strip()
                print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç LLaMA: {answer[:50]}...")
                return answer
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ LLaMA —Å–µ—Ä–≤–µ—Ä–∞: {response.status_code} - {response.text}")
                return None
                
        except requests.exceptions.ConnectionError:
            print("‚ùå –ù–µ —É–¥–∞–µ—Ç—Å—è –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ LLaMA —Å–µ—Ä–≤–µ—Ä—É. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –æ–Ω –∑–∞–ø—É—â–µ–Ω.")
            return None
        except requests.exceptions.Timeout:
            print("‚è∞ –¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ –∫ LLaMA —Å–µ—Ä–≤–µ—Ä—É. –°–µ—Ä–≤–µ—Ä –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω.")
            return None
        except Exception as e:
            print(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ LLaMA: {e}")
            return None

    def check_server_health(self) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å LLaMA —Å–µ—Ä–≤–µ—Ä–∞
        """
        try:
            response = requests.get(f"{self.server_url}/health", timeout=5)
            return response.status_code == 200
        except requests.exceptions.RequestException:
            return False


async def test_llama_connection():
    """
    –¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ LLaMA —Å–µ—Ä–≤–µ—Ä—É
    """
    client = LlamaClient()
    
    if client.check_server_health():
        print("‚úÖ LLaMA —Å–µ—Ä–≤–µ—Ä –¥–æ—Å—Ç—É–ø–µ–Ω")
        response = await client.send_message("–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –¥–µ–ª–∞?")
        if response:
            print(f"ü§ñ –û—Ç–≤–µ—Ç: {response}")
        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç")
    else:
        print("‚ùå LLaMA —Å–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")


if __name__ == "__main__":
    import asyncio
    asyncio.run(test_llama_connection()) 