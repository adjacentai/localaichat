aiogram==3.3.0
llama-cpp-python[server]
honcho
uvicorn
aiohttp==3.9.1
requests==2.31.0
httpx==0.25.2
aiofiles==23.2.1
python-dotenv==1.0.0